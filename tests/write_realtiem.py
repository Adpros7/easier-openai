code = """from __future__ import annotations\n\nimport asyncio\nimport base64\nimport logging\nimport threading\nimport wave\nfrom dataclasses import dataclass\nfrom http.server import BaseHTTPRequestHandler, ThreadingHTTPServer\nfrom pathlib import Path\nfrom typing import Any, AsyncIterator, Dict, Iterable, Iterator, Optional, Union\n\nimport audioop  # type: ignore[attr-defined]\nfrom openai import AsyncOpenAI, OpenAI\n\ntry:  # pragma: no cover - optional dependency\n    import pyaudio  # type: ignore\nexcept ImportError:  # pragma: no cover - optional dependency\n    pyaudio = None\n\n\nlogger = logging.getLogger(__name__)\n\n# The OpenAI Python SDK exposes realtime connection helpers and webhook verification utilities. \n# \n\n\n@dataclass(slots=True)\nclass AudioProfile:\n    \'\'\'PCM audio profile used for both capture and playback.\'\'\'\n\n    sample_rate: int = 16_000\n    sample_width: int = 2\n    channels: int = 1\n    chunk_duration_seconds: float = 0.2\n\n    @property\n    def frames_per_chunk(self) -> int:\n        return int(self.sample_rate * self.chunk_duration_seconds)\n\n    @property\n    def bytes_per_frame(self) -> int:\n        return self.sample_width * self.channels\n\n    @property\n    def bytes_per_chunk(self) -> int:\n        return self.frames_per_chunk * self.bytes_per_frame\n\n\nAudioInput = Union[str, Path, Any]\n\n\nclass _WebhookHTTPServer(ThreadingHTTPServer):\n    \'\'\'HTTP server that routes verified webhook events into an asyncio queue.\'\'\'\n\n    allow_reuse_address = True\n\n    def __init__(\n        self,\n        server_address: tuple[str, int],\n        RequestHandlerClass: type[BaseHTTPRequestHandler],\n        *,\n        loop: asyncio.AbstractEventLoop,\n        async_queue: \'asyncio.Queue[dict[str, Any] | BaseException]\',\n        sync_client: OpenAI,\n        path: str,\n    ) -> None:\n        super().__init__(server_address, RequestHandlerClass)\n        self.loop = loop\n        self.async_queue = async_queue\n        self.sync_client = sync_client\n        self.expected_path = path\n\n\ndef _make_handler() -> type[BaseHTTPRequestHandler]:\n    class Handler(BaseHTTPRequestHandler):\n        server: _WebhookHTTPServer  # type: ignore[assignment]\n\n        def log_message(self, *args: Any, **kwargs: Any) -> None:  # pragma: no cover - silence\n            logger.debug(\'Webhook server log: %s\', args)\n\n        def do_POST(self) -> None:  # noqa: N802\n            if self.path != self.server.expected_path:\n                self.send_response(404)\n                self.end_headers()\n                return\n            length = int(self.headers.get(\'Content-Length\', \'0\'))\n            payload = self.rfile.read(length).decode(\'utf-8\')\n            try:\n                event = self.server.sync_client.webhooks.unwrap(payload, dict(self.headers))\n            except Exception as exc:  # pragma: no cover - verification failures\n            
    logger.exception(\'Invalid webhook signature\')\n                self.send_response(400)\n                self.end_headers()\n                self.wfile.write(str(exc).encode(\'utf-8\'))\n                return\n            self.send_response(204)\n            self.end_headers()\n            event_dict = event.model_dump(mode=\'json\')\n            self.server.loop.call_soon_threadsafe(self.server.async_queue.put_nowait, event_dict)\n\n    return Handler\n\n\nclass WebhookEventReceiver:\n    \'\'\'Runs a lightweight HTTP server to collect webhook events asynchronously.\'\'\'\n\n    _sentinel: dict[str, Any] = {\'type\': \'__sentinel__\'}\n\n    def __init__(\n        self,\n        *,\n        loop: asyncio.AbstractEventLoop,\n        host: str,\n        port: int,\n        path: str,\n        api_key: Optional[str],\n        webhook_secret: str,\n        url_override: Optional[str] = None,\n    ) -> None:\n        self.loop = loop\n        self.host = host\n        self.path = path if path.startswith(\'/\') else f\'/{path}\'\n        self._async_queue: \'asyncio.Queue[dict[str, Any] | BaseException]\' = asyncio.Queue()\n        self._server: Optional[_WebhookHTTPServer] = None\n        self._thread: Optional[threading.Thread] = None\n        self._closed = False\n        self.webhook_secret = webhook_secret\n        self._url_override = url_override\n        self._api_key = api_key\n        self._port = port\n\n    async def __aenter__(self) -> \'WebhookEventReceiver\':\n        self.start()\n        return self\n\n    async def __aexit__(self, exc_type: Any, exc: Any, tb: Any) -> None:\n        self.close()\n\n    def __aiter__(self) -> AsyncIterator[dict[str, Any]]:\n        return self._event_iterator()\n\n    def start(self) -> None:\n        if self._server is not None:\n            
return\n        sync_client = OpenAI(api_key=self._api_key, webhook_secret=self.webhook_secret)\n        handler = _make_handler()\n        self._server = _WebhookHTTPServer(\n            (self.host, self._port),\n            handler,\n            loop=self.loop,\n            async_queue=self._async_queue,\n            sync_client=sync_client,\n            path=self.path,\n        )\n        actual_host, actual_port = self._server.server_address\n        self._resolved_url = (\n            self._url_override\n            if self._url_override\n            else f\'http://{actual_host if actual_host not in ('0.0.0.0', '::') else '127.0.0.1'}:{actual_port}{self.path}\'\n        )\n        self._thread = threading.Thread(target=self._server.serve_forever, daemon=True)\n        self._thread.start()\n        logger.debug(\'Webhook server listening on %s\', self._resolved_url)\n\n    def close(self) -> None:\n        if self._closed:\n            return\n        self._closed = True\n        if self._server is not None:\n            self._server.shutdown()\n            self._server.server_close()\n        if self._thread is not None:\n            self._thread.join(timeout=2)\n        self.loop.call_soon_threadsafe(self._async_queue.put_nowait, self._sentinel)\n\n    @property\n    def url(self) -> str:\n        if not hasattr(self, \'_resolved_url\'):\n            raise RuntimeError(\'Webhook server has not been started\')\n        return self._resolved_url\n\n    async def _event_iterator(self) -> AsyncIterator[dict[str, Any]]:\n        while True:\n            item = await self._async_queue.get()\n            if item is self._sentinel:\n                break\n            if isinstance(item, BaseException):\n                raise item\n            yield item\n\n\ndef _is_pyaudio_stream(source: Any) -> bool:\n    return bool(pyaudio is not None and isinstance(source, pyaudio.Stream))\n\n\ndef _iter_audio_chunks(\n    source: AudioInput,\n    profile: AudioProfile,\n    *,\n    max_capture_seconds: Optional[float] = None,\n) -> Iterable[bytes]:\n    if _is_pyaudio_stream(source):\n        frames_target = (\n            int(max_capture_seconds * profile.sample_rate)\n            
if max_capture_seconds is not None\n            else None\n        )\n        frames_sent = 0\n        while True:\n            try:\n                chunk = source.read(profile.frames_per_chunk, exception_on_overflow=False)\n            except Exception:\n                break\n            if not chunk:\n                break\n            frames_sent += len(chunk) // profile.bytes_per_frame\n            yield chunk\n            if frames_target is not None and frames_sent >= frames_target:\n                break\n        return\n\n    if hasattr(source, \'read\') and callable(source.read):\n        data = source.read()\n    else:\n        path = Path(str(source)).expanduser()\n        with path.open(\'rb\') as handle:\n            data = handle.read()\n\n    with wave.open(Path(\'input.wav\'), \'rb\') if False else wave.open(  # pragma: no cover - placeholder to satisfy type checker\n        wave.BytesIO(data) if hasattr(wave, \'BytesIO\') else wave.open  # type: ignore[misc]\n    ):\n        pass  # This block is never executed; retain placeholder to avoid static analysis issues.\n\n    with wave.open(memoryview(data)) as wav_reader:\n        frames = wav_reader.readframes(wav_reader.getnframes())\n        sample_width = wav_reader.getsampwidth()\n        channels = wav_reader.getnchannels()\n        sample_rate = wav_reader.getframerate()\n\n    mono = (\n        audioop.tomono(frames, sample_width, 1, 1) if channels > 1 else frames\n    )\n    converted = (\n        audioop.lin2lin(mono, sample_width, profile.sample_width)\n        if sample_width != profile.sample_width\n        else mono\n    )\n    resampled, _ = (\n        audioop.ratecv(\n            converted,\n            profile.sample_width,\n            1,\n            sample_rate,\n            profile.sample_rate,\n            None,\n        )\n        if sample_rate != profile.sample_rate\n        else (converted, None)\n    )\n    chunk_size = profile.bytes_per_chunk\n    for offset in range(0, len(resampled), chunk_size):\n        yield resampled[offset : offset + chunk_size]\n\n\ndef _encode_pcm_chunk(chunk: bytes) -> str:\n    return base64.b64encode(chunk).decode(\'ascii\')\n\n\ndef _extract_text(event: dict[str, Any]) -> list[str]:\n    text_fragments: list[str] = []\n    payload = event.get(\'data\') or {}\n    delta = payload.get(\'delta\') or event.get(\'delta\')\n\n    def add_text(value: Any) -> None:\n        if isinstance(value, str) and value:\n            text_fragments.append(value)\n\n    if isinstance(delta, dict):\n        for key in (\'text\', \'output_text\'):\n            add_text(delta.get(key))\n    elif isinstance(delta, str):\n        add_text(delta)\n\n    for key in (\'text\', \'output_text\'):\n        add_text(payload.get(key))\n\n    segments = payload.get(\'segments\')\n    if isinstance(segments, list):\n        for segment in segments:\n            if isinstance(segment, dict):\n                add_text(segment.get(\'text\'))\n\n    return text_fragments\n\n\ndef _extract_audio_bytes(event: dict[str, Any]) -> Optional[bytes]:\n    payload = event.get(\'data\') or {}\n    delta = payload.get(\'delta\') or event.get(\'delta\')\n    candidates = []\n    if isinstance(delta, dict):\n        candidates.extend(\n            delta.get(key) for key in (\'audio\', \'chunk\', \'data\')\n        )\n    candidates.extend(payload.get(key) for key in (\'audio\', \'chunk\'))\n    for candidate in candidates:\n        if isinstance(candidate, str) and candidate:\n            try:\n                return base64.b64decode(candidate)\n            except Exception:\n                continue\n    return None\n\n\ndef _apply_session_overrides(base: dict[str, Any], overrides: Optional[dict[str, Any]]) -> dict[str, Any]:\n    if not overrides:\n        return base\n    merged = {**overrides}\n    for key, value in base.items():\n        if key not in merged:\n            merged[key] = value\n        elif isinstance(value, dict) and isinstance(merged[key], dict):\n            merged[key] = {**value, **merged[key]}\n    return merged\n\n\ndef voice_to_text(\n    source: AudioInput,\n    *,\n    model: str = \'gpt-4o-realtime-preview\',\n    api_key: Optional[str] = None,\n    webhook_secret: str,\n    webhook_host: str = \'0.0.0.0\',\n    webhook_port: int = 0,\n    webhook_path: str = \'/openai-webhook\',\n    external_webhook_url: Optional[str] = None,\n    audio_profile: AudioProfile = AudioProfile(),\n    instructions: Optional[str] = None,\n    session_overrides: Optional[dict[str, Any]] = None,\n    max_capture_seconds: Optional[float] = None,\n) -> Iterator[str]:\n    \'\'\'Stream text deltas emitted via webhook while feeding audio into a realtime model.\'\'\'\n\n    output_queue: \'queue.Queue[str | BaseException | object]\' = queue.Queue()\n    sentinel: object = object()\n\n    async def runner() -> None:\n        try:\n            await _voice_to_text_async(\n                source=source,\n                model=model,\n                api_key=api_key,\n                webhook_secret=webhook_secret,\n                webhook_host=webhook_host,\n                webhook_port=webhook_port,\n                
webhook_path=webhook_path,\n                external_webhook_url=external_webhook_url,\n                audio_profile=audio_profile,\n                instructions=instructions,\n              
  session_overrides=session_overrides,\n                output_queue=output_queue,\n            
    sentinel=sentinel,\n                max_capture_seconds=max_capture_seconds,\n            )\n        except Exception as exc:\n            logger.exception(\'voice_to_text encountered an error\')\n            output_queue.put(exc)\n        finally:\n            output_queue.put(sentinel)\n\n    thread = threading.Thread(target=lambda: asyncio.run(runner()), daemon=True)\n    thread.start()\n\n    def iterator() -> Iterator[str]:\n        try:\n            while True:\n                item = output_queue.get()\n                if item is sentinel:\n                  
  break\n                if isinstance(item, BaseException):\n                    raise item\n                yield item  # type: ignore[misc]\n        finally:\n            thread.join(timeout=2)\n\n    return iterator()\n\n\nasync def _voice_to_text_async(\n    *,\n    source: AudioInput,\n    model: str,\n    api_key: Optional[str],\n    webhook_secret: str,\n    webhook_host: str,\n    webhook_port: int,\n    webhook_path: str,\n    external_webhook_url: Optional[str],\n    audio_profile: AudioProfile,\n    instructions: Optional[str],\n    session_overrides: Optional[dict[str, Any]],\n    output_queue: \'queue.Queue[str | BaseException | object]\',\n    sentinel: object,\n    max_capture_seconds: Optional[float],\n) -> None:\n    loop = asyncio.get_running_loop()\n    async with WebhookEventReceiver(\n        loop=loop,\n        host=webhook_host,\n        port=webhook_port,\n        path=webhook_path,\n        api_key=api_key,\n        webhook_secret=webhook_secret,\n        url_override=external_webhook_url,\n    ) as receiver:\n        async_client = AsyncOpenAI(api_key=api_key)\n        async with async_client.realtime.connect(model=model) as connection:\n            session_payload: Dict[str, Any] = {\n                
\'modalities\': [\'audio\', \'text\'],\n                \'webhook\': {\n                    \'url\': receiver.url,\n                    \'secret\': webhook_secret,\n                },\n            }\n            if instructions:\n                session_payload[\'instructions\'] = instructions\n            session_payload = _apply_session_overrides(session_payload, session_overrides)\n            await connection.session.update(session=session_payload)\n\n            async def consume_events() -> None:\n                try:\n                    async for event in receiver:\n                        event_type = event.get(\'type\', \'\')\n                        if event_type.startswith(\'response\'):\n                            for fragment in _extract_text(event):\n                                output_queue.put(fragment)\n                           
 if event_type in {\'response.completed\', \'response.done\'}:\n                                
break\n                        elif event_type == \'response.error\':\n                         
   message = event.get(\'data\', {}).get(\'message\', \'Unknown error\')\n                      
      raise RuntimeError(f\'Realtime error: {message}\')\n                finally:\n            
        output_queue.put(sentinel)\n\n            consumer_task = asyncio.create_task(consume_events())\n\n            for chunk in _iter_audio_chunks(source, audio_profile, max_capture_seconds=max_capture_seconds):\n                await connection.input_audio_buffer.append(\n          
          input_audio={\'audio\': _encode_pcm_chunk(chunk)}\n                )\n            await connection.input_audio_buffer.commit()\n            await connection.response.create(response={\'modalities\': [\'text\']})\n            await consumer_task\n\n\ndef voice_to_voice(\n    source: AudioInput,\n    *,\n    model: str = \'gpt-4o-realtime-preview\',\n    api_key: Optional[str] = None,\n    webhook_secret: str,\n    webhook_host: str = \'0.0.0.0\',\n    webhook_port: int = 0,\n    webhook_path: str = \'/openai-webhook\',\n    external_webhook_url: Optional[str] = None,\n    audio_profile: AudioProfile = AudioProfile(),\n    instructions: Optional[str] = None,\n    session_overrides: Optional[dict[str, Any]] = None,\n    voice: Optional[str] = None,\n    max_capture_seconds: Optional[float] = None,\n    playback_device_index: Optional[int] = None,\n) -> None:\n    \'\'\'Send audio from microphone or file to a realtime model and play the streamed response.\'\'\'\n\n    asyncio.run(\n        _voice_to_voice_async(\n            source=source,\n            model=model,\n            api_key=api_key,\n            webhook_secret=webhook_secret,\n            webhook_host=webhook_host,\n            webhook_port=webhook_port,\n            webhook_path=webhook_path,\n            external_webhook_url=external_webhook_url,\n            audio_profile=audio_profile,\n            instructions=instructions,\n            session_overrides=session_overrides,\n            voice=voice,\n            max_capture_seconds=max_capture_seconds,\n            playback_device_index=playback_device_index,\n        )\n    )\n\n\nasync def _voice_to_voice_async(\n    *,\n    source: AudioInput,\n    model: str,\n    api_key: Optional[str],\n    webhook_secret: str,\n    webhook_host: str,\n    webhook_port: int,\n    webhook_path: str,\n    external_webhook_url: Optional[str],\n    audio_profile: AudioProfile,\n    instructions: Optional[str],\n    session_overrides: Optional[dict[str, Any]],\n    voice: Optional[str],\n    max_capture_seconds: Optional[float],\n    playback_device_index: Optional[int],\n) -> None:\n    if pyaudio is None:\n        raise RuntimeError(\'PyAudio is required for voice playback; install pyaudio first.\')\n\n    pa_instance = pyaudio.PyAudio()\n    output_stream = pa_instance.open(\n        format=pa_instance.get_format_from_width(audio_profile.sample_width),\n        channels=audio_profile.channels,\n        rate=audio_profile.sample_rate,\n        output=True,\n        output_device_index=playback_device_index,\n    )\n\n    loop = asyncio.get_running_loop()\n    async with WebhookEventReceiver(\n        loop=loop,\n        host=webhook_host,\n        port=webhook_port,\n        path=webhook_path,\n        api_key=api_key,\n        webhook_secret=webhook_secret,\n        url_override=external_webhook_url,\n    ) as receiver:\n        async_client = AsyncOpenAI(api_key=api_key)\n        async with async_client.realtime.connect(model=model) as connection:\n            session_payload: Dict[str, Any] = {\n          
      \'modalities\': [\'audio\', \'text\'],\n                \'webhook\': {\n                  
  \'url\': receiver.url,\n                    \'secret\': webhook_secret,\n                },\n            }\n            if instructions:\n                session_payload[\'instructions\'] = instructions\n            if voice:\n                session_payload[\'voice\'] = voice\n            session_payload = _apply_session_overrides(session_payload, session_overrides)\n           
 await connection.session.update(session=session_payload)\n\n            async def consume_events() -> None:\n                async for event in receiver:\n                    event_type = event.get(\'type\', \'\')\n                    if event_type.startswith(\'response.audio.delta\') or event_type.startswith(\'response.output_audio.delta\'):\n                        chunk = _extract_audio_bytes(event)\n                        if chunk:\n                            output_stream.write(chunk)\n                    elif event_type.startswith(\'response\'):\n              
          if event_type == \'response.error\':\n                            message = event.get(\'data\', {}).get(\'message\', \'Unknown error\')\n                            raise RuntimeError(f\'Realtime error: {message}\')\n                        if event_type in {\'response.completed\', \'response.done\'}:\n                            break\n\n            consumer_task = asyncio.create_task(consume_events())\n\n            for chunk in _iter_audio_chunks(source, audio_profile, max_capture_seconds=max_capture_seconds):\n                await connection.input_audio_buffer.append(\n                    input_audio={\'audio\': _encode_pcm_chunk(chunk)}\n          
      )\n            await connection.input_audio_buffer.commit()\n            await connection.response.create(response={\'modalities\': [\'audio\', \'text\']})\n\n            try:\n         
       await consumer_task\n            finally:\n                output_stream.stop_stream()\n                output_stream.close()\n                pa_instance.terminate()\n"
"""

with open("realtime.py", "w") as f:
    f.write(code)